{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "\n",
    "from util.dask import to_csv\n",
    "\n",
    "CHUNK_SIZE = 1000\n",
    "\n",
    "dtypes = {\n",
    "    'Index': 'int64',\n",
    "    'AnonID': 'str',\n",
    "    'Query': 'str',\n",
    "    'QueryTime': 'str',\n",
    "    'ItemRank': 'str',\n",
    "    'ClickURL': 'str',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_query(query):\n",
    "    yield query\n",
    "    \n",
    "    for i in range(1, len(query)):\n",
    "        yield query[:-i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_dataset(in_file, out_file):\n",
    "    chunks = pd.read_csv(in_file, index_col=0, usecols=[0,2], dtype=dtypes, chunksize=CHUNK_SIZE)\n",
    "    \n",
    "    first = True\n",
    "    # Count the number of chunks in this file\n",
    "    num_chunks = int(sum(1 for row in open(in_file, 'r')) / CHUNK_SIZE) + 1\n",
    "    chunk_id = iter(range(1, num_chunks+1))\n",
    "    \n",
    "    with open(out_file, 'w') as f: f.write('')\n",
    "\n",
    "    for df in chunks:\n",
    "        print(\"Processing chunk {} of {}\".format(next(chunk_id), num_chunks), end=\"\\r\")\n",
    "\n",
    "        # Any empty query is not interesting\n",
    "        df.dropna(inplace=True)\n",
    "\n",
    "        # 1. Apply suffix_ngrams, creates a list of ngrams for each row\n",
    "        # 2. Apply pd.Series, creates a series for this list\n",
    "        # 3. Merge the applied series with the dataframe\n",
    "        # 4. Reset the index, make it available for selection\n",
    "        # 5. Melt with the index and Query as id, this flattens the ngrams list\n",
    "        # 6. Drop the variable column, they are not interesting anymore\n",
    "        df = df.Query.apply(sample_query).apply(pd.Series)\\\n",
    "             .merge(df, right_index = True, left_index = True)\\\n",
    "             .reset_index()\\\n",
    "             .melt(id_vars = ['Index', 'Query'], value_name = \"prefix\")\\\n",
    "             .drop(['variable'], axis = 1)\n",
    "\n",
    "        df.to_csv(out_file, mode='a', header=first, index=False)\n",
    "        first = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dataset('test_normalized.csv', 'test_sampled.csv')\n",
    "sample_dataset('validation_normalized.csv', 'validation_sampled.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
