{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep the data\n",
    "\n",
    "Extract all the files from `AOL_search_data_leak_2006.zip` and concat them into a single file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import shutil\n",
    "import gzip\n",
    "import glob\n",
    "import os.path\n",
    "import pandas as pd\n",
    "\n",
    "DATA_ZIP_FILE = 'AOL_search_data_leak_2006.zip'\n",
    "DATA_DIR = 'AOL-user-ct-collection'\n",
    "OUT_FILE = 'total_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(OUT_FILE):\n",
    "    name = input('Output file already exists, do you want to continue? (y/n): ')\n",
    "    if name != 'y': exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check if the zip file is in this directory\n",
    "\n",
    "if not os.path.isfile(DATA_ZIP_FILE):\n",
    "    raise Exception(DATA_ZIP_FILE + ' not found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract zip file\n",
    "\n",
    "archive = zipfile.ZipFile(DATA_ZIP_FILE)\n",
    "archive.extractall()\n",
    "archive.close()\n",
    "\n",
    "shutil.rmtree('__MACOSX', ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract gz files inside zip file\n",
    "\n",
    "gz_files = glob.glob(DATA_DIR + '/*.gz')\n",
    "for gz_filename in gz_files:\n",
    "    txt_filename = gz_filename[:-3]\n",
    "    with gzip.open(gz_filename, 'rb') as f_in, open(txt_filename, 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concat all files into a single file\n",
    "\n",
    "txt_files = glob.glob(DATA_DIR + '/user*.txt')\n",
    "\n",
    "dtypes = {\n",
    "    'AnonID': 'str',\n",
    "    'Query': 'str',\n",
    "    'QueryTime': 'str',\n",
    "    'ItemRank': 'str',\n",
    "    'ClickUrl': 'str',\n",
    "}\n",
    "\n",
    "files = (pd.read_csv(f, sep=\"\\t\", dtype=dtypes) for f in txt_files)\n",
    "    \n",
    "frame = pd.concat(files, ignore_index=True)\n",
    "\n",
    "frame.sort_values('QueryTime', inplace=True)\n",
    "\n",
    "frame.to_csv(OUT_FILE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
