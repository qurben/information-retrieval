{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Model\n",
    "\n",
    "Train a LambdaMART model using xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "TRAINING = 'training_features.csv'\n",
    "TEST = 'test_features.csv'\n",
    "VALIDATION = 'validation_features.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_matrix(candidates):\n",
    "    candidates = candidates.drop('Prefix', axis=1)\n",
    "    candidates = candidates.drop('Suffix', axis=1)\n",
    "    dmatrix = xgb.DMatrix(candidates.drop('Query', axis=1), candidates['Query'])\n",
    "    return dmatrix\n",
    "\n",
    "def train(train, validation):\n",
    "    dtrain = to_matrix(train)\n",
    "    dvalidation = to_matrix(validation)\n",
    "\n",
    "    params = {\n",
    "        'objective' : 'rank:pairwise',\n",
    "        'eval_metric': 'error',\n",
    "    }\n",
    "\n",
    "    return xgb.train(\n",
    "        params, \n",
    "        dtrain, \n",
    "        num_boost_round=300, \n",
    "        evals=[(dvalidation, 'validation')], \n",
    "        early_stopping_rounds=30, \n",
    "        verbose_eval=True\n",
    "    )\n",
    "\n",
    "def rank(test, model):\n",
    "    dmatrix = to_matrix(test)\n",
    "    return model.predict(test, ntree_limit=model.best_ntree_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the datasets used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(TRAINING, low_memory=False)\n",
    "validation_data = pd.read_csv(VALIDATION, low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model using these sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train(training_data, validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete the datasets from the memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del training_data\n",
    "del validation_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the test data and verify the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(TEST, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = rank(test_data, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
