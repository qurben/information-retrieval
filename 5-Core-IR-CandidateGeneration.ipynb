{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Candidate Generation\n",
    "\n",
    "> for a given prefix we extract the end-term as shown in Figure 1. We match all the suffixes that\n",
    "> start with the end-term from our precomputed set. These selected suffixes are appended to the\n",
    "> prefix to generate synthetic suggestion candidates. For example, the prefix \"cheap flights fro\"\n",
    "> is matched with the suffix \"from seattle\" to generate the candidate \"cheap flights from seattle\".\n",
    "> Note that many of these synthetic suggestion candidates are likely to not have been observed by\n",
    "> the search engine before. We merge these synthetic suggestions with the set of candidates\n",
    "> selected from the list of historically popular queries. This combined set of candidates is used\n",
    "> for ranking as we will describe in Sec 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "\n",
    "POPULAR_SUFFIX_FILE = 'popular_suffix.csv'\n",
    "BASE_FILE = 'training_normalized.csv'\n",
    "OUT_FILE = 'training_sampled.csv'\n",
    "\n",
    "CHUNK_SIZE = 10000\n",
    "N_POPULAR_SUFFIX = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix_df = pd.read_csv(POPULAR_SUFFIX_FILE, index_col='ngram', nrows=N_POPULAR_SUFFIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def end_term(query):\n",
    "    \"\"\"\n",
    "    end_term('cheapest flight fro') = 'fro'\n",
    "    end_term('cheapest flight from') = 'from'\n",
    "    end_term('cheapest flight from ') = 'from '\n",
    "    end_term('cheapest flight from n') = 'n'\n",
    "    \"\"\"\n",
    "    if query.endswith(' '):\n",
    "        return query[query[:-1].rfind(' ')+1:]\n",
    "    else:\n",
    "        return query[query.rfind(' ')+1:]\n",
    "\n",
    "def match_end_term(end_term):\n",
    "    return list(suffix_df[suffix_df.index.str.startswith(end_term)].index)\n",
    "    \n",
    "def apply_end_term(row):\n",
    "    query = original_query = row.Query.iat[0]\n",
    "        \n",
    "    candidates = [{\n",
    "        'Prefix': query,\n",
    "        'Suffix': '',\n",
    "        'Query': query\n",
    "    }]\n",
    "    \n",
    "    while query.find(' ') != -1: # There is more than one word\n",
    "        term = end_term(query)\n",
    "        suffixes = match_end_term(term)\n",
    "                \n",
    "        for suffix in suffixes[:10]:\n",
    "            new_query = query + suffix[len(term):]\n",
    "            \n",
    "            if new_query != original_query or True:\n",
    "                candidates.append({\n",
    "                    'Prefix': query,\n",
    "                    'Suffix': suffix,\n",
    "                    'Query': new_query\n",
    "                })\n",
    "        \n",
    "        query = query[:query.rfind(' ')]\n",
    "    \n",
    "    return pd.DataFrame(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(OUT_FILE, 'w') as the_file: the_file.write('Index,Prefix,Query,Suffix\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    'Index': 'int64',\n",
    "    'AnonID': 'str',\n",
    "    'Query': 'str',\n",
    "    'QueryTime': 'str',\n",
    "    'ItemRank': 'str',\n",
    "    'ClickURL': 'str',\n",
    "}\n",
    "\n",
    "# only load index and Query\n",
    "df = pd.read_csv(BASE_FILE, index_col='Index', dtype=dtypes, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Any empty query is not interesting\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df = df.groupby(df.columns.tolist(), group_keys=False).apply(apply_end_term)\n",
    "df = df.reset_index()\n",
    "df = df.drop('index', axis=1) # drop de oude index\n",
    "\n",
    "df.to_csv(OUT_FILE, mode='a', header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
