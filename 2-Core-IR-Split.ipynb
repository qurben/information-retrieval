{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting data\n",
    "\n",
    "Split the data into different parts according to the definition in the paper\n",
    "\n",
    "> The query impressions on both the testbeds are divided into four temporally separate partitions\n",
    "> (background, training, validation and test). On theAOL testbed we use all the data from 1 March,\n",
    "> 2006 to 30 April, 2006 as the background data. We sample queries from the next two weeks for\n",
    "> training, and from each of the following two weeks for validation and test, respectively. On the\n",
    "> Bing testbed we sample data from the logs from April, 2015 and use the first week of data for\n",
    "> background, the second week for training, the third for validation and the fourth for testing. We\n",
    "> normalize all the queries ineach of these datasets by removing any punctuation characters and\n",
    "> converting them to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os.path\n",
    "from util.normalize import normalize_csv\n",
    "\n",
    "CHUNK_SIZE = 100000\n",
    "IN_FILE = 'total_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('background.csv'):\n",
    "    name = input('Output file already exists, do you want to continue? (y/n): ')\n",
    "    if name != 'y': exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_start = \"2006-03-01 00:00:00\"\n",
    "background_end = \"2006-03-01 23:59:59\"\n",
    "training_end = \"2006-03-02 23:59:59\"\n",
    "validation_end = \"2006-03-03 12:59:59\"\n",
    "test_end = \"2006-03-03 23:59:59\"\n",
    "\n",
    "dtypes = {\n",
    "    'Index': 'int64',\n",
    "    'AnonID': 'str',\n",
    "    'Query': 'str',\n",
    "    'QueryTime': 'str',\n",
    "    'ItemRank': 'str',\n",
    "    'ClickUrl': 'str',\n",
    "}\n",
    "\n",
    "files = ['background.csv', 'training.csv', 'validation.csv', 'test.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(IN_FILE, 'r') as in_file:\n",
    "    header = in_file.readline()\n",
    "\n",
    "for file in files:\n",
    "    with open(file, 'w') as the_file:\n",
    "        the_file.write(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_chunks = int(sum(1 for row in open(IN_FILE, 'r')) / CHUNK_SIZE) + 1\n",
    "chunks = pd.read_csv(IN_FILE, dtype=dtypes, index_col='Index', chunksize=CHUNK_SIZE)\n",
    "chunk_id = iter(range(1, num_chunks+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in chunks:\n",
    "    print(\"Processing chunk {} of {}\".format(next(chunk_id), num_chunks), end=\"\\r\")\n",
    "\n",
    "    background = df[(df['QueryTime'] > data_start) & (df['QueryTime'] < background_end)]\n",
    "    training = df[(df['QueryTime'] > background_end) & (df['QueryTime'] < training_end)]\n",
    "    validation = df[(df['QueryTime'] > training_end) & (df['QueryTime'] < validation_end)]\n",
    "    test = df[(df['QueryTime'] > validation_end) & (df['QueryTime'] < test_end)]\n",
    "\n",
    "    background.to_csv('background.csv', mode='a', header=False)\n",
    "    training.to_csv('training.csv', mode='a', header=False)\n",
    "    validation.to_csv('validation.csv', mode='a', header=False)\n",
    "    test.to_csv('test.csv', mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_csv('background.csv', 'background_normalized.csv')\n",
    "normalize_csv('training.csv', 'training_normalized.csv')\n",
    "normalize_csv('validation.csv', 'validation_normalized.csv')\n",
    "normalize_csv('test.csv', 'test_normalized.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
